{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://docs.google.com/presentation/d/1dizKPtp9hkuTwVDzoGZdYQb_61ULSsSUvaFfDFuhIc4/edit#slide=id.g2dfad34716_0_318"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs and Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data flow graphs I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow separates the definition of computations from their execution:\n",
    "- Phase 1: assemble a graph\n",
    "- Phase 2: use a session to execute the operations in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's a tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An n-dimensional array:\n",
    "- 0-d tensor: scalar\n",
    "- 1-d tensor: vector\n",
    "- 2-d tensor: matrix\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data flow graphs II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3` and `5` are tensors, these will represent the edges of the data flow graph. The nodes of this graph (which can be visualized in TensorBoard) are the operators, variables and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output is not 8!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to get the value of `a`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **session**, assign it to variable `sess`, so we can call it later. Within the session, evaluate the graph to fetch the value of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The session will look at the graph and think: 'Hmm, how can I get the value of `a`?' Then it computes all the nodes that lead to `a`. Note that the above code can also be written as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About `tf.Session()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Session` object encapsulates the environment in which `Operation` objects are executed, and `Tensor` objects are evaluated. `Session` will also allocate memory to store the current values of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3)\n",
    "    print(op3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625\n"
     ]
    }
   ],
   "source": [
    "add_op  = tf.add(x, y)\n",
    "mul_op  = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op  = tf.pow(add_op, mul_op)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op)\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, because we only want the value of `pow_op` and `pow_op` doesn't depend on useless, `Session` won't compute the value of `useless` in order to save computational effort! If `useless` however is useful in some way, we can feed `tf.Session.run()` with a list of tensors whose values we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625 10\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    z, not_useless = sess.run([pow_op, useless])\n",
    "    print(z, not_useless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (b) `tf.add()` gives back a `Tensor` not the actual result of the operation. This is because of the way TensorFlow splits definition and execution.\n",
    "- (c) Done.\n",
    "- (d) Save computational effort, break computation into small, differential pieces to facilitate auto-differentiation, facilitate distributed computation and because it is analogous to the structure of many ML models.\n",
    "- (d) See code cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.392\n"
     ]
    }
   ],
   "source": [
    "u = 2\n",
    "v = 3\n",
    "w = 4\n",
    "\n",
    "num_base = tf.add(v, w)\n",
    "den_base = tf.add(u, v)\n",
    "\n",
    "num_pow = tf.pow(num_base, u)\n",
    "den_pow = tf.pow(den_base, v)\n",
    "\n",
    "fraction = tf.divide(num_pow, den_pow)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(fraction)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
